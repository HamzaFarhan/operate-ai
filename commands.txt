# Run fastapi app

cd src/operate_ai

uv run fastapi dev api.py

# Run streamlit app

cd src/operate_ai

uv run streamlit run app.py 



*************************** Update Deployments ***************************
# Login to VM:
gcloud compute ssh --zone "us-central1-c" "apps-demo" --project "dreamai-pocs"

# Become root:
sudo su -

# Update Code:

rm -r /opt/data/operatea-app/data/workspaces/

cd /opt/apps-demo/operateai-app/excel-mcp-server && git pull && cd /opt/apps-demo/operateai-app/operate-ai && git pull && cd /opt/apps-demo/operateai-app/ && docker build . -f operate-ai/Dockerfile_ui_app -t gcr.io/dreamai-pocs/operateai-ui-app:v1 && docker build . -f operate-ai/Dockerfile_bkend_app -t gcr.io/dreamai-pocs/operateai-bkend-app:v1 && docker-compose down && docker-compose up -d


# Check logs:
docker logs -f operateai-bkend-app
docker logs -f operateai-ui-app


https://operateai.dreamai.io/

The workspace ws1 already has the data uploaded
You can just create a new thread and start playing with it
The typical flow it does is:
1. Run an SQL query
2. Show the results and ask for review
3. Continue after:
    - A 30 secondtimeout
    - User feedback
    - User clicks on the "Continue" button
4. Runs steps 1-3 until all analysis is complete
5. Compiles the results into a workbook if asked to or if it thinks it's a good idea
6. Returns the workbook to the user
7. Returns the final response to the user

From what Iâ€™ve seen, steps 5-6 can take some time (~5 minutes), so if you're happy with the analysis so far, you can keep it running and come back to it later.

